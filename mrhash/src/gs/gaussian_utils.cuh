/*
 * SPDX-FileCopyrightText: 2023 Janusch Patas
 * SPDX-FileCopyrightText: 2024 Smart Robotics Lab, Technical University of Munich
 * SPDX-FileCopyrightText: 2024 Jiaxin Wei
 * All rights reserved. Some of the code is derived from 3D Gaussian Splatting for Real-Time Radiance Field Rendering software by
 * Inria and MPII.
 */

#ifndef GS_GAUSSIAN_UTIL_HPP
#define GS_GAUSSIAN_UTIL_HPP

#include <Eigen/Dense>
#include <climits>
#include <condition_variable>
#include <filesystem>
#include <fstream>
#include <mutex>
#include <nvml.h>
#include <opencv2/opencv.hpp>
#include <queue>
#include <random>
#include <tinyply.h>
#include <torch/torch.h>

using Slice = torch::indexing::Slice;

namespace gs {
  struct DataPacket {
    int ID          = -1;
    int global_iter = -1;
    int num_kf;
    int num_splats;
    float fps;
    cv::Mat rgb;
    cv::Mat depth;
    cv::Mat rendered_rgb;
  };

  class DataQueue {
  public:
    void push(DataPacket data) {
      std::lock_guard<std::mutex> lock(_mtx);
      _queue.push(std::move(data));
      _cv.notify_one(); // Notify one waiting thread
    }

    DataPacket pop() {
      std::unique_lock<std::mutex> lock(_mtx);
      _cv.wait(lock, [this]() { return !_queue.empty(); }); // Wait until queue is not empty
      DataPacket data = std::move(_queue.front());
      _queue.pop();
      return data;
    }

    int getSize() {
      return _queue.size();
    }

  private:
    std::queue<DataPacket> _queue;
    std::mutex _mtx;
    std::condition_variable _cv;
  };

  // 1D Gaussian kernel
  static inline torch::Tensor gaussian(int window_size, float sigma) {
    torch::Tensor gauss = torch::empty(window_size);
    for (int x = 0; x < window_size; ++x) {
      gauss[x] = std::exp(-(std::pow(static_cast<float>(x - std::floor(window_size / 2.f)), 2)) / (2.f * sigma * sigma));
    }
    return gauss / gauss.sum();
  }

  static inline torch::Tensor create_window(int window_size, int channel) {
    auto _1D_window = gaussian(window_size, 1.5).unsqueeze(1);
    auto _2D_window = _1D_window.mm(_1D_window.t()).unsqueeze(0).unsqueeze(0);
    return _2D_window.expand({channel, 1, window_size, window_size}).contiguous();
  }

  const int window_size  = 11;
  const int channel      = 3;
  const auto conv_window = create_window(window_size, channel).to(torch::kFloat32).to(torch::kCUDA, true);

  static const double C0        = 0.28209479177387814;
  static const double C1        = 0.4886025119029199;
  static std::vector<double> C2 = {1.0925484305920792,
                                   -1.0925484305920792,
                                   0.31539156525252005,
                                   -1.0925484305920792,
                                   0.5462742152960396};
  static std::vector<double> C3 = {-0.5900435899266435,
                                   2.890611442640554,
                                   -0.4570457994644658,
                                   0.3731763325901154,
                                   -0.4570457994644658,
                                   1.445305721320277,
                                   -0.5900435899266435};
  static std::vector<double> C4 = {2.5033429417967046,
                                   -1.7701307697799304,
                                   0.9461746957575601,
                                   -0.6690465435572892,
                                   0.10578554691520431,
                                   -0.6690465435572892,
                                   0.47308734787878004,
                                   -1.7701307697799304,
                                   0.6258357354491761};

  static inline torch::Tensor RGB2SH(const torch::Tensor& rgb) {
    return (rgb - 0.5f) / static_cast<float>(C0);
  }

  struct Point {
    float x;
    float y;
    float z;
  };

  struct Color {
    unsigned char r;
    unsigned char g;
    unsigned char b;
  };

  struct Camera {
    int width;
    int height;
    float fov_x;
    float fov_y;
    torch::Tensor T_W2C;
    torch::Tensor full_proj_matrix;
    torch::Tensor cam_center;
  };

  /**
   * Calculates the inverse sigmoid of a tensor element-wise.
   *
   * @param x The input tensor.
   * @return The tensor with the inverse sigmoid of each element.
   */
  static inline torch::Tensor inverse_sigmoid(torch::Tensor x) {
    return torch::log(x / (1 - x));
  }

  /**
   * @brief Strips the lower diagonal elements of a 3x3 matrix and returns them as a 1D tensor of size (N, 6).
   *
   * @param L A 3D tensor of size (N, 3, 3) representing a batch of 3x3 matrices.
   * @return A 2D tensor of size (N, 6) representing the upper diagonal elements of each matrix in L.
   */
  static inline torch::Tensor strip_lowerdiag(torch::Tensor L) {
    torch::Tensor uncertainty = torch::zeros({L.size(0), 6}, torch::dtype(torch::kFloat).device(torch::kCUDA));

    uncertainty.index_put_({Slice(), 0}, L.index({Slice(), 0, 0}));
    uncertainty.index_put_({Slice(), 1}, L.index({Slice(), 0, 1}));
    uncertainty.index_put_({Slice(), 2}, L.index({Slice(), 0, 2}));
    uncertainty.index_put_({Slice(), 3}, L.index({Slice(), 1, 1}));
    uncertainty.index_put_({Slice(), 4}, L.index({Slice(), 1, 2}));
    uncertainty.index_put_({Slice(), 5}, L.index({Slice(), 2, 2}));
    return uncertainty;
  }

  /**
   * @brief Strips the symmetric part of a tensor.
   *
   * This function takes an input tensor and returns the tensor with the symmetric part removed.
   *
   * @param sym The input tensor.
   * @return The tensor with the symmetric part removed.
   */
  static inline torch::Tensor strip_symmetric(torch::Tensor sym) {
    return strip_lowerdiag(sym);
  }

  /**
   * @brief Builds a rotation matrix from a tensor of quaternions.
   *
   * @param r Tensor of quaternions with shape (N, 4).
   * @return Tensor of rotation matrices with shape (N, 3, 3).
   */
  static inline torch::Tensor build_rotation(torch::Tensor r) {
    torch::Tensor norm = torch::sqrt(torch::sum(r.pow(2), 1));
    torch::Tensor q    = r / norm.unsqueeze(-1);

    torch::Tensor R  = torch::zeros({q.size(0), 3, 3}, torch::device(torch::kCUDA));
    torch::Tensor r0 = q.index({Slice(), 0});
    torch::Tensor x  = q.index({Slice(), 1});
    torch::Tensor y  = q.index({Slice(), 2});
    torch::Tensor z  = q.index({Slice(), 3});

    R.index_put_({Slice(), 0, 0}, 1 - 2 * (y * y + z * z));
    R.index_put_({Slice(), 0, 1}, 2 * (x * y - r0 * z));
    R.index_put_({Slice(), 0, 2}, 2 * (x * z + r0 * y));
    R.index_put_({Slice(), 1, 0}, 2 * (x * y + r0 * z));
    R.index_put_({Slice(), 1, 1}, 1 - 2 * (x * x + z * z));
    R.index_put_({Slice(), 1, 2}, 2 * (y * z - r0 * x));
    R.index_put_({Slice(), 2, 0}, 2 * (x * z - r0 * y));
    R.index_put_({Slice(), 2, 1}, 2 * (y * z + r0 * x));
    R.index_put_({Slice(), 2, 2}, 1 - 2 * (x * x + y * y));
    return R;
  }

  /**
   * Builds a scaling-rotation matrix from the given scaling and rotation tensors.
   *
   * @param s The scaling tensor of shape (N, 3) where N is the number of scaling factors.
   * @param r The rotation tensor of shape (N, 4) where N is the number of rotation angles.
   * @return The scaling-rotation matrix of shape (N, 3, 3) where N is the number of scaling-rotation matrices.
   */
  static inline torch::Tensor build_scaling_rotation(torch::Tensor s, torch::Tensor r) {
    torch::Tensor L = torch::zeros({s.size(0), 3, 3}, torch::dtype(torch::kFloat).device(torch::kCUDA));
    torch::Tensor R = build_rotation(r);

    L.index_put_({Slice(), 0, 0}, s.index({Slice(), 0}));
    L.index_put_({Slice(), 1, 1}, s.index({Slice(), 1}));
    L.index_put_({Slice(), 2, 2}, s.index({Slice(), 2}));

    L = R.matmul(L);
    return L;
  }

  static inline torch::Tensor getProjectionMatrix(int W, int H, float fx, float fy, float cx, float cy) {
    Eigen::Matrix4f P = Eigen::Matrix4f::Zero();
    P(0, 0)           = 2 * fx / W;
    P(1, 1)           = 2 * fy / H;
    P(0, 2)           = 2 * (cx / W) - 1;
    P(1, 2)           = 2 * (cy / H) - 1;
    P(2, 2)           = 0;
    P(2, 3)           = 0;
    P(3, 2)           = 1;

    // create torch::Tensor from Eigen::Matrix
    auto PTensor = torch::from_blob(P.data(), {4, 4}, torch::kFloat);
    return PTensor.clone();
  }

  static inline void Write_output_ply(const std::filesystem::path& file_path,
                                      const std::vector<torch::Tensor>& tensors,
                                      const std::vector<std::string>& attribute_names) {
    tinyply::PlyFile plyFile;

    size_t attribute_offset = 0; // An offset to track the attribute names

    for (size_t i = 0; i < tensors.size(); ++i) {
      // Calculate the number of columns in the tensor.
      size_t columns = tensors[i].size(1);

      std::vector<std::string> current_attributes;
      for (size_t j = 0; j < columns; ++j) {
        current_attributes.push_back(attribute_names[attribute_offset + j]);
      }

      plyFile.add_properties_to_element("vertex",
                                        current_attributes,
                                        tinyply::Type::FLOAT32,
                                        tensors[i].size(0),
                                        reinterpret_cast<uint8_t*>(tensors[i].data_ptr<float>()),
                                        tinyply::Type::INVALID,
                                        0);

      attribute_offset += columns; // Increase the offset for the next tensor.
    }

    std::filebuf fb;
    fb.open(file_path, std::ios::out | std::ios::binary);
    std::ostream outputStream(&fb);
    plyFile.write(outputStream, true); // 'true' for binary format
  }

  static inline float psnr_metric(const torch::Tensor& rendered_img, const torch::Tensor& gt_img) {
    torch::Tensor squared_diff = (rendered_img - gt_img).pow(2);
    torch::Tensor mse_val      = squared_diff.view({rendered_img.size(0), -1}).mean(1, true);
    return (20.f * torch::log10(1.0 / mse_val.sqrt())).mean().item<float>();
  }

  static inline std::vector<int> get_random_indices(int max_index) {
    std::vector<int> indices(max_index);
    std::iota(indices.begin(), indices.end(), 0);
    // Shuffle the vector
    std::random_device rd;
    std::shuffle(indices.begin(), indices.end(), std::default_random_engine(rd()));
    std::reverse(indices.begin(), indices.end());
    return indices;
  }

  // Function to get the memory usage of the GPU
  static inline auto getGPUMemoryUsage(int gpu_id = 0) {
    nvmlReturn_t result;
    nvmlDevice_t device;
    nvmlMemory_t memory;

    // Initialize NVML library
    result = nvmlInit();
    if (NVML_SUCCESS != result) {
      std::cerr << "Failed to initialize NVML: " << nvmlErrorString(result) << "\n";
      return ULLONG_MAX;
    }

    // Get the GPU handle
    result = nvmlDeviceGetHandleByIndex(gpu_id, &device);
    if (NVML_SUCCESS != result) {
      std::cerr << "Failed to get handle for device " << std::to_string(gpu_id) << ": " << nvmlErrorString(result) << "\n";
      nvmlShutdown();
      return ULLONG_MAX;
    }

    // Get memory information
    result = nvmlDeviceGetMemoryInfo(device, &memory);
    if (NVML_SUCCESS != result) {
      std::cerr << "Failed to get memory info: " << nvmlErrorString(result) << "\n";
      nvmlShutdown();
      return ULLONG_MAX;
    }

    auto used_gpu_memory = memory.used / (1024 * 1024);

    // Shutdown NVML library
    nvmlShutdown();

    return used_gpu_memory;
  }
} // namespace gs

#endif // GS_GAUSSIAN_UTIL_HPP
